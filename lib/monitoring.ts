/**
 * ESM Platform - Real-time Performance Monitoring and Health Checks
 * Comprehensive monitoring for 300+ concurrent users with alerting
 */

import { memoryMonitor } from './memory-management';\nimport { metricsCollector } from './api-optimization';\nimport { checkDatabaseHealth, getQueryMetrics } from './database';\n\n// ============================================\n// PERFORMANCE METRICS COLLECTION\n// ============================================\n\nexport interface SystemMetrics {\n  timestamp: number;\n  performance: {\n    memoryUsage: {\n      used: number;\n      total: number;\n      limit: number;\n      percentage: number;\n    };\n    responseTime: {\n      average: number;\n      p95: number;\n      p99: number;\n    };\n    database: {\n      connected: boolean;\n      latency: number;\n      poolStats?: {\n        totalCount: number;\n        idleCount: number;\n        waitingCount: number;\n      };\n    };\n    api: {\n      totalRequests: number;\n      errorRate: number;\n      cacheHitRate: number;\n      rateLimitBlocks: number;\n    };\n  };\n  health: {\n    overall: 'healthy' | 'warning' | 'critical' | 'error';\n    services: {\n      database: 'healthy' | 'warning' | 'critical' | 'error';\n      api: 'healthy' | 'warning' | 'critical' | 'error';\n      memory: 'healthy' | 'warning' | 'critical' | 'error';\n      frontend: 'healthy' | 'warning' | 'critical' | 'error';\n    };\n  };\n  alerts: Alert[];\n}\n\nexport interface Alert {\n  id: string;\n  level: 'info' | 'warning' | 'error' | 'critical';\n  message: string;\n  category: 'performance' | 'memory' | 'database' | 'api' | 'security';\n  timestamp: number;\n  resolved?: boolean;\n  resolvedAt?: number;\n}\n\nclass MetricsCollector {\n  private metrics: SystemMetrics[] = [];\n  private maxMetricsHistory = 1000;\n  private alerts: Map<string, Alert> = new Map();\n  private thresholds = {\n    memoryWarning: 0.7,     // 70% memory usage\n    memoryCritical: 0.85,   // 85% memory usage\n    responseWarning: 1000,  // 1 second response time\n    responseCritical: 3000, // 3 seconds response time\n    errorRateWarning: 0.05, // 5% error rate\n    errorRateCritical: 0.15, // 15% error rate\n    dbLatencyWarning: 100,  // 100ms database latency\n    dbLatencyCritical: 500  // 500ms database latency\n  };\n  \n  async collectMetrics(): Promise<SystemMetrics> {\n    const timestamp = Date.now();\n    \n    // Collect memory metrics\n    const memoryStats = memoryMonitor.recordMemoryUsage();\n    const memoryUsage = memoryStats ? {\n      used: memoryStats.usedJSHeapSize,\n      total: memoryStats.totalJSHeapSize,\n      limit: memoryStats.jsHeapSizeLimit,\n      percentage: memoryStats.usedJSHeapSize / memoryStats.jsHeapSizeLimit\n    } : {\n      used: 0,\n      total: 0,\n      limit: 0,\n      percentage: 0\n    };\n    \n    // Collect API metrics\n    const apiMetrics = metricsCollector.getMetrics();\n    \n    // Collect database metrics\n    const dbHealth = await checkDatabaseHealth();\n    const queryMetrics = getQueryMetrics();\n    \n    // Calculate health status\n    const health = this.calculateHealthStatus({\n      memoryUsage,\n      apiMetrics,\n      dbHealth,\n      queryMetrics\n    });\n    \n    // Generate alerts\n    const alerts = this.generateAlerts({\n      memoryUsage,\n      apiMetrics,\n      dbHealth,\n      responseTime: {\n        average: apiMetrics.averageResponseTime,\n        p95: apiMetrics.p95ResponseTime,\n        p99: apiMetrics.p99ResponseTime\n      }\n    });\n    \n    const metrics: SystemMetrics = {\n      timestamp,\n      performance: {\n        memoryUsage,\n        responseTime: {\n          average: apiMetrics.averageResponseTime,\n          p95: apiMetrics.p95ResponseTime,\n          p99: apiMetrics.p99ResponseTime\n        },\n        database: {\n          connected: dbHealth.connected,\n          latency: dbHealth.latency || 0,\n          poolStats: dbHealth.poolStats\n        },\n        api: {\n          totalRequests: apiMetrics.totalRequests,\n          errorRate: apiMetrics.totalRequests > 0 \n            ? apiMetrics.errorCount / apiMetrics.totalRequests \n            : 0,\n          cacheHitRate: apiMetrics.cacheHitRate,\n          rateLimitBlocks: apiMetrics.rateLimitBlocks\n        }\n      },\n      health,\n      alerts: Array.from(alerts.values()).filter(alert => !alert.resolved)\n    };\n    \n    // Store metrics\n    this.metrics.push(metrics);\n    if (this.metrics.length > this.maxMetricsHistory) {\n      this.metrics = this.metrics.slice(-this.maxMetricsHistory);\n    }\n    \n    return metrics;\n  }\n  \n  private calculateHealthStatus(data: {\n    memoryUsage: SystemMetrics['performance']['memoryUsage'];\n    apiMetrics: any;\n    dbHealth: any;\n    queryMetrics: any;\n  }): SystemMetrics['health'] {\n    const services = {\n      memory: this.getMemoryHealth(data.memoryUsage),\n      api: this.getApiHealth(data.apiMetrics),\n      database: this.getDatabaseHealth(data.dbHealth),\n      frontend: this.getFrontendHealth(data.memoryUsage)\n    };\n    \n    // Determine overall health\n    const healthLevels = Object.values(services);\n    const overall = healthLevels.includes('critical') ? 'critical'\n      : healthLevels.includes('error') ? 'error'\n      : healthLevels.includes('warning') ? 'warning'\n      : 'healthy';\n    \n    return { overall, services };\n  }\n  \n  private getMemoryHealth(memoryUsage: SystemMetrics['performance']['memoryUsage']): 'healthy' | 'warning' | 'critical' | 'error' {\n    if (memoryUsage.percentage > this.thresholds.memoryCritical) return 'critical';\n    if (memoryUsage.percentage > this.thresholds.memoryWarning) return 'warning';\n    return 'healthy';\n  }\n  \n  private getApiHealth(apiMetrics: any): 'healthy' | 'warning' | 'critical' | 'error' {\n    const errorRate = apiMetrics.totalRequests > 0 \n      ? apiMetrics.errorCount / apiMetrics.totalRequests \n      : 0;\n    \n    if (errorRate > this.thresholds.errorRateCritical) return 'critical';\n    if (errorRate > this.thresholds.errorRateWarning) return 'warning';\n    if (apiMetrics.averageResponseTime > this.thresholds.responseCritical) return 'critical';\n    if (apiMetrics.averageResponseTime > this.thresholds.responseWarning) return 'warning';\n    \n    return 'healthy';\n  }\n  \n  private getDatabaseHealth(dbHealth: any): 'healthy' | 'warning' | 'critical' | 'error' {\n    if (!dbHealth.connected) return 'error';\n    if (dbHealth.latency > this.thresholds.dbLatencyCritical) return 'critical';\n    if (dbHealth.latency > this.thresholds.dbLatencyWarning) return 'warning';\n    \n    return 'healthy';\n  }\n  \n  private getFrontendHealth(memoryUsage: SystemMetrics['performance']['memoryUsage']): 'healthy' | 'warning' | 'critical' | 'error' {\n    // Frontend health is primarily based on memory usage in browser\n    return this.getMemoryHealth(memoryUsage);\n  }\n  \n  private generateAlerts(data: {\n    memoryUsage: SystemMetrics['performance']['memoryUsage'];\n    apiMetrics: any;\n    dbHealth: any;\n    responseTime: SystemMetrics['performance']['responseTime'];\n  }): Map<string, Alert> {\n    const newAlerts = new Map<string, Alert>();\n    const timestamp = Date.now();\n    \n    // Memory alerts\n    if (data.memoryUsage.percentage > this.thresholds.memoryCritical) {\n      newAlerts.set('memory-critical', {\n        id: 'memory-critical',\n        level: 'critical',\n        message: `Critical memory usage: ${Math.round(data.memoryUsage.percentage * 100)}%`,\n        category: 'memory',\n        timestamp\n      });\n    } else if (data.memoryUsage.percentage > this.thresholds.memoryWarning) {\n      newAlerts.set('memory-warning', {\n        id: 'memory-warning',\n        level: 'warning',\n        message: `High memory usage: ${Math.round(data.memoryUsage.percentage * 100)}%`,\n        category: 'memory',\n        timestamp\n      });\n    }\n    \n    // Response time alerts\n    if (data.responseTime.average > this.thresholds.responseCritical) {\n      newAlerts.set('response-critical', {\n        id: 'response-critical',\n        level: 'critical',\n        message: `Critical response time: ${Math.round(data.responseTime.average)}ms`,\n        category: 'performance',\n        timestamp\n      });\n    } else if (data.responseTime.average > this.thresholds.responseWarning) {\n      newAlerts.set('response-warning', {\n        id: 'response-warning',\n        level: 'warning',\n        message: `Slow response time: ${Math.round(data.responseTime.average)}ms`,\n        category: 'performance',\n        timestamp\n      });\n    }\n    \n    // Database alerts\n    if (!data.dbHealth.connected) {\n      newAlerts.set('database-error', {\n        id: 'database-error',\n        level: 'critical',\n        message: 'Database connection lost',\n        category: 'database',\n        timestamp\n      });\n    } else if (data.dbHealth.latency > this.thresholds.dbLatencyCritical) {\n      newAlerts.set('database-latency-critical', {\n        id: 'database-latency-critical',\n        level: 'critical',\n        message: `Critical database latency: ${data.dbHealth.latency}ms`,\n        category: 'database',\n        timestamp\n      });\n    } else if (data.dbHealth.latency > this.thresholds.dbLatencyWarning) {\n      newAlerts.set('database-latency-warning', {\n        id: 'database-latency-warning',\n        level: 'warning',\n        message: `High database latency: ${data.dbHealth.latency}ms`,\n        category: 'database',\n        timestamp\n      });\n    }\n    \n    // API error rate alerts\n    const errorRate = data.apiMetrics.totalRequests > 0 \n      ? data.apiMetrics.errorCount / data.apiMetrics.totalRequests \n      : 0;\n    \n    if (errorRate > this.thresholds.errorRateCritical) {\n      newAlerts.set('api-error-critical', {\n        id: 'api-error-critical',\n        level: 'critical',\n        message: `Critical API error rate: ${Math.round(errorRate * 100)}%`,\n        category: 'api',\n        timestamp\n      });\n    } else if (errorRate > this.thresholds.errorRateWarning) {\n      newAlerts.set('api-error-warning', {\n        id: 'api-error-warning',\n        level: 'warning',\n        message: `High API error rate: ${Math.round(errorRate * 100)}%`,\n        category: 'api',\n        timestamp\n      });\n    }\n    \n    // Merge with existing alerts, resolving old ones\n    this.resolveOldAlerts(newAlerts);\n    \n    // Add new alerts\n    for (const [id, alert] of newAlerts) {\n      this.alerts.set(id, alert);\n    }\n    \n    return this.alerts;\n  }\n  \n  private resolveOldAlerts(newAlerts: Map<string, Alert>): void {\n    const now = Date.now();\n    \n    for (const [id, alert] of this.alerts) {\n      if (!newAlerts.has(id) && !alert.resolved) {\n        // Alert condition no longer exists, resolve it\n        alert.resolved = true;\n        alert.resolvedAt = now;\n      }\n    }\n  }\n  \n  getLatestMetrics(): SystemMetrics | null {\n    return this.metrics[this.metrics.length - 1] || null;\n  }\n  \n  getMetricsHistory(count: number = 100): SystemMetrics[] {\n    return this.metrics.slice(-count);\n  }\n  \n  getActiveAlerts(): Alert[] {\n    return Array.from(this.alerts.values()).filter(alert => !alert.resolved);\n  }\n  \n  getAllAlerts(): Alert[] {\n    return Array.from(this.alerts.values());\n  }\n  \n  resolveAlert(alertId: string): void {\n    const alert = this.alerts.get(alertId);\n    if (alert && !alert.resolved) {\n      alert.resolved = true;\n      alert.resolvedAt = Date.now();\n    }\n  }\n  \n  clearResolvedAlerts(olderThanMs: number = 3600000): void { // 1 hour default\n    const cutoff = Date.now() - olderThanMs;\n    \n    for (const [id, alert] of this.alerts) {\n      if (alert.resolved && alert.resolvedAt && alert.resolvedAt < cutoff) {\n        this.alerts.delete(id);\n      }\n    }\n  }\n}\n\nexport const systemMetrics = new MetricsCollector();\n\n// ============================================\n// REAL-TIME MONITORING SERVICE\n// ============================================\n\nclass MonitoringService {\n  private isRunning = false;\n  private intervalId: NodeJS.Timeout | null = null;\n  private subscribers: Set<(metrics: SystemMetrics) => void> = new Set();\n  private alertHandlers: Set<(alerts: Alert[]) => void> = new Set();\n  \n  start(intervalMs: number = 30000): void {\n    if (this.isRunning) return;\n    \n    this.isRunning = true;\n    \n    const collectAndNotify = async () => {\n      try {\n        const metrics = await systemMetrics.collectMetrics();\n        \n        // Notify subscribers\n        this.subscribers.forEach(callback => {\n          try {\n            callback(metrics);\n          } catch (error) {\n            console.error('Error in metrics subscriber:', error);\n          }\n        });\n        \n        // Notify alert handlers if there are active alerts\n        const activeAlerts = metrics.alerts;\n        if (activeAlerts.length > 0) {\n          this.alertHandlers.forEach(callback => {\n            try {\n              callback(activeAlerts);\n            } catch (error) {\n              console.error('Error in alert handler:', error);\n            }\n          });\n        }\n        \n        // Log critical alerts to console\n        const criticalAlerts = activeAlerts.filter(alert => alert.level === 'critical');\n        if (criticalAlerts.length > 0) {\n          console.error('🚨 CRITICAL ALERTS:', criticalAlerts.map(a => a.message));\n        }\n        \n      } catch (error) {\n        console.error('Error collecting metrics:', error);\n      }\n    };\n    \n    // Initial collection\n    collectAndNotify();\n    \n    // Set up interval\n    this.intervalId = setInterval(collectAndNotify, intervalMs);\n    \n    console.log(`📊 Monitoring service started (interval: ${intervalMs}ms)`);\n  }\n  \n  stop(): void {\n    if (!this.isRunning) return;\n    \n    this.isRunning = false;\n    \n    if (this.intervalId) {\n      clearInterval(this.intervalId);\n      this.intervalId = null;\n    }\n    \n    console.log('📊 Monitoring service stopped');\n  }\n  \n  subscribe(callback: (metrics: SystemMetrics) => void): () => void {\n    this.subscribers.add(callback);\n    return () => this.subscribers.delete(callback);\n  }\n  \n  onAlert(callback: (alerts: Alert[]) => void): () => void {\n    this.alertHandlers.add(callback);\n    return () => this.alertHandlers.delete(callback);\n  }\n  \n  getStatus(): {\n    running: boolean;\n    subscribers: number;\n    alertHandlers: number;\n    lastMetrics: SystemMetrics | null;\n    activeAlerts: number;\n  } {\n    return {\n      running: this.isRunning,\n      subscribers: this.subscribers.size,\n      alertHandlers: this.alertHandlers.size,\n      lastMetrics: systemMetrics.getLatestMetrics(),\n      activeAlerts: systemMetrics.getActiveAlerts().length\n    };\n  }\n}\n\nexport const monitoringService = new MonitoringService();\n\n// ============================================\n// HEALTH CHECK ENDPOINTS\n// ============================================\n\nexport interface HealthCheckResult {\n  status: 'healthy' | 'warning' | 'critical' | 'error';\n  timestamp: number;\n  uptime: number;\n  version: string;\n  environment: string;\n  checks: {\n    database: {\n      status: 'healthy' | 'warning' | 'critical' | 'error';\n      latency: number;\n      connected: boolean;\n      details?: any;\n    };\n    memory: {\n      status: 'healthy' | 'warning' | 'critical' | 'error';\n      usage: number;\n      limit: number;\n      percentage: number;\n    };\n    api: {\n      status: 'healthy' | 'warning' | 'critical' | 'error';\n      responseTime: number;\n      errorRate: number;\n      requestCount: number;\n    };\n  };\n  alerts: Alert[];\n}\n\nexport async function performHealthCheck(): Promise<HealthCheckResult> {\n  const startTime = Date.now();\n  \n  // Get latest metrics\n  const metrics = await systemMetrics.collectMetrics();\n  \n  const result: HealthCheckResult = {\n    status: metrics.health.overall,\n    timestamp: startTime,\n    uptime: process.uptime ? process.uptime() * 1000 : Date.now() - startTime,\n    version: process.env.npm_package_version || '1.0.0',\n    environment: process.env.NODE_ENV || 'development',\n    checks: {\n      database: {\n        status: metrics.health.services.database,\n        latency: metrics.performance.database.latency,\n        connected: metrics.performance.database.connected,\n        details: metrics.performance.database.poolStats\n      },\n      memory: {\n        status: metrics.health.services.memory,\n        usage: metrics.performance.memoryUsage.used,\n        limit: metrics.performance.memoryUsage.limit,\n        percentage: metrics.performance.memoryUsage.percentage\n      },\n      api: {\n        status: metrics.health.services.api,\n        responseTime: metrics.performance.responseTime.average,\n        errorRate: metrics.performance.api.errorRate,\n        requestCount: metrics.performance.api.totalRequests\n      }\n    },\n    alerts: metrics.alerts\n  };\n  \n  return result;\n}\n\n// ============================================\n// BROWSER PERFORMANCE MONITORING\n// ============================================\n\nexport interface BrowserMetrics {\n  timestamp: number;\n  navigation?: PerformanceNavigationTiming;\n  resources?: PerformanceResourceTiming[];\n  memory?: {\n    usedJSHeapSize: number;\n    totalJSHeapSize: number;\n    jsHeapSizeLimit: number;\n  };\n  vitals: {\n    fcp?: number;  // First Contentful Paint\n    lcp?: number;  // Largest Contentful Paint\n    fid?: number;  // First Input Delay\n    cls?: number;  // Cumulative Layout Shift\n  };\n}\n\nexport function collectBrowserMetrics(): BrowserMetrics {\n  const metrics: BrowserMetrics = {\n    timestamp: Date.now(),\n    vitals: {}\n  };\n  \n  // Navigation timing\n  const navigation = performance.getEntriesByType('navigation')[0] as PerformanceNavigationTiming;\n  if (navigation) {\n    metrics.navigation = navigation;\n  }\n  \n  // Resource timing (limit to prevent memory bloat)\n  const resources = performance.getEntriesByType('resource').slice(-50) as PerformanceResourceTiming[];\n  if (resources.length > 0) {\n    metrics.resources = resources;\n  }\n  \n  // Memory info\n  if ('memory' in performance && (performance as any).memory) {\n    metrics.memory = (performance as any).memory;\n  }\n  \n  // Web Vitals (if available)\n  try {\n    // First Contentful Paint\n    const fcpEntry = performance.getEntriesByName('first-contentful-paint')[0];\n    if (fcpEntry) {\n      metrics.vitals.fcp = fcpEntry.startTime;\n    }\n    \n    // Largest Contentful Paint\n    const lcpEntries = performance.getEntriesByType('largest-contentful-paint');\n    if (lcpEntries.length > 0) {\n      metrics.vitals.lcp = lcpEntries[lcpEntries.length - 1].startTime;\n    }\n    \n  } catch (error) {\n    console.warn('Error collecting Web Vitals:', error);\n  }\n  \n  return metrics;\n}\n\n// Auto-start monitoring in browser environment\nif (typeof window !== 'undefined') {\n  // Wait for page load before starting monitoring\n  window.addEventListener('load', () => {\n    setTimeout(() => {\n      monitoringService.start(30000); // 30 second intervals\n      \n      // Log monitoring status\n      console.log('📊 Browser monitoring started');\n    }, 1000);\n  });\n  \n  // Stop monitoring on page unload\n  window.addEventListener('beforeunload', () => {\n    monitoringService.stop();\n  });\n}\n\nexport default {\n  SystemMetrics,\n  Alert,\n  systemMetrics,\n  monitoringService,\n  performHealthCheck,\n  collectBrowserMetrics\n};